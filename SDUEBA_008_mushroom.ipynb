{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afix0/BP/blob/main/SDUEBA_008_mushroom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4\n",
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "id": "er-0sQBWjv-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee1b243-ad24-4349-d1e2-3f66a10853a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.26.4\n",
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ja2FYADmALao"
      },
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "import numpy as np\n",
        "import scipy\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import sklearn\n",
        "from sklearn.preprocessing import normalize, LabelEncoder, OneHotEncoder\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "VJ6p0USOiIRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb73377a-9483-4f41-f359-10f0af5691e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo\n",
        "!pip install subgroups\n",
        "from ucimlrepo import fetch_ucirepo\n"
      ],
      "metadata": {
        "id": "XUMPL-JCiKl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691fb6c1-772b-4aa8-c03d-80a616dcd051"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Requirement already satisfied: subgroups in /usr/local/lib/python3.11/dist-packages (0.1.10)\n",
            "Requirement already satisfied: pandas>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from subgroups) (2.2.2)\n",
            "Requirement already satisfied: bitarray>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from subgroups) (3.2.0)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from subgroups) (0.14.4)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.4->subgroups) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.4->subgroups) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.4->subgroups) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1.4->subgroups) (2025.1)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->subgroups) (1.13.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->subgroups) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->subgroups) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.4->subgroups) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rzben4ha9pYo"
      },
      "outputs": [],
      "source": [
        "#SDUEBA Parameters:\n",
        "\"\"\"\n",
        "vector_space_dimention  ... dimention of the embedding vector space\n",
        "n_clusters              ... number of clusters to be found\n",
        "max_depth               ... maximal depth of the decision tree\n",
        "test_size               ... size of the test set for training the decision tree\n",
        "mixed_threashold        ... threshold for classifying a cluster as mixed\n",
        "\"\"\"\n",
        "\n",
        "vector_space_dimension = 36\n",
        "n_clusters = 23\n",
        "clustering_method = \"agglomerative\"      #\"agglomerative\"/\"spherical_kmeans\"\n",
        "max_depth = 2\n",
        "test_size = 0.2\n",
        "mixed_threshold = 0.9\n",
        "tree_accuracy_threshold = 0.95\n",
        "\n",
        "target_value = 'poisonous'\n",
        "\n",
        "#Quality metric parameters\n",
        "description_length_limit = 2\n",
        "difference_limit = 0\n",
        "subgroup_size_limit = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kiTDW9F9J_tX"
      },
      "outputs": [],
      "source": [
        "#Data augemntation\n",
        "\n",
        "def preprocess_mushroom_data(df):\n",
        "\n",
        "    mapping = {\n",
        "    'cap-shape': {'b': 'bell', 'c': 'conical', 'x': 'convex', 'f': 'flat', 'k': 'knobbed', 's': 'sunken'},\n",
        "    'cap-surface': {'f': 'fibrous', 'g': 'grooves', 'y': 'scaly', 's': 'smooth'},\n",
        "    'cap-color': {'n': 'brown', 'b': 'buff', 'c': 'cinnamon', 'g': 'gray', 'r': 'green', 'p': 'pink', 'u': 'purple', 'e': 'red', 'w': 'white', 'y': 'yellow'},\n",
        "    'bruises': {'t': 'bruises', 'f': 'no bruises'},\n",
        "    'odor': {'a': 'almond', 'l': 'anise', 'c': 'creosote', 'y': 'fishy', 'f': 'foul', 'm': 'musty', 'n': 'none', 'p': 'pungent', 's': 'spicy'},\n",
        "    'gill-attachment': {'a': 'attached', 'd': 'descending', 'f': 'free', 'n': 'notched'},\n",
        "    'gill-spacing': {'c': 'close', 'w': 'crowded', 'd': 'distant'},\n",
        "    'gill-size': {'b': 'broad', 'n': 'narrow'},\n",
        "    'gill-color': {'k': 'black', 'n': 'brown', 'b': 'buff', 'h': 'chocolate', 'g': 'gray', 'r': 'green', 'o': 'orange', 'p': 'pink', 'u': 'purple', 'e': 'red', 'w': 'white', 'y': 'yellow'},\n",
        "    'stalk-shape': {'e': 'enlarging', 't': 'tapering'},\n",
        "    'stalk-root': {'b': 'bulbous', 'c': 'club', 'u': 'cup', 'e': 'equal', 'z': 'rhizomorphs', 'r': 'rooted', '?': 'missing'},\n",
        "    'stalk-surface-above-ring': {'f': 'fibrous', 'y': 'scaly', 'k': 'silky', 's': 'smooth'},\n",
        "    'stalk-surface-below-ring': {'f': 'fibrous', 'y': 'scaly', 'k': 'silky', 's': 'smooth'},\n",
        "    'stalk-color-above-ring': {'n': 'brown', 'b': 'buff', 'c': 'cinnamon', 'g': 'gray', 'o': 'orange', 'p': 'pink', 'e': 'red', 'w': 'white', 'y': 'yellow'},\n",
        "    'stalk-color-below-ring': {'n': 'brown', 'b': 'buff', 'c': 'cinnamon', 'g': 'gray', 'o': 'orange', 'p': 'pink', 'e': 'red', 'w': 'white', 'y': 'yellow'},\n",
        "    'veil-type': {'p': 'partial', 'u': 'universal'},\n",
        "    'veil-color': {'n': 'brown', 'o': 'orange', 'w': 'white', 'y': 'yellow'},\n",
        "    'ring-number': {'n': 'none', 'o': 'one', 't': 'two'},\n",
        "    'ring-type': {'c': 'cobwebby', 'e': 'evanescent', 'f': 'flaring', 'l': 'large', 'n': 'none', 'p': 'pendant', 's': 'sheathing', 'z': 'zone'},\n",
        "    'spore-print-color': {'k': 'black', 'n': 'brown', 'b': 'buff', 'h': 'chocolate', 'r': 'green', 'o': 'orange', 'u': 'purple', 'w': 'white', 'y': 'yellow'},\n",
        "    'population': {'a': 'abundant', 'c': 'clustered', 'n': 'numerous', 's': 'scattered', 'v': 'several', 'y': 'solitary'},\n",
        "    'habitat': {'g': 'grasses', 'l': 'leaves', 'm': 'meadows', 'p': 'paths', 'u': 'urban', 'w': 'waste', 'd': 'woods'}\n",
        "}\n",
        "\n",
        "    for column, mapping in mapping.items():\n",
        "        df[column] = df[column].replace(mapping)\n",
        "\n",
        "    return df\n",
        "\n",
        "mapping_targets = {'p': 'poisonous', 'e': 'edible'}\n",
        "\n",
        "data = fetch_ucirepo(id=73)\n",
        "features_raw = preprocess_mushroom_data(pd.DataFrame(data=data.data.features))\n",
        "target_df = pd.DataFrame(data=data.data.targets)\n",
        "target_df.columns = ['class']\n",
        "target_df['class'] = target_df['class'].map(mapping_targets)\n",
        "# features_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "GtAP4WR2Ar3o"
      },
      "outputs": [],
      "source": [
        "#Data augemntation sentence creation\n",
        "#TRAINING ON ALL DATA!!!\n",
        "training_df = pd.merge(features_raw, target_df, left_index=True, right_index=True)\n",
        "\n",
        "for column in training_df.columns:\n",
        "    split_columns = column.split(\"_\")\n",
        "    jointed_columns = ' '.join(split_columns)\n",
        "    training_df[column] = training_df[column].apply(lambda x: f\"{jointed_columns} is {x}\")\n",
        "\n",
        "sentences = []\n",
        "for i in range(len(training_df)):\n",
        "    sentence = []\n",
        "    for word in training_df.iloc[i]:\n",
        "        sentence.append(word)\n",
        "    sentences.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SEJJZRjUBXQF"
      },
      "outputs": [],
      "source": [
        "#Word2Vec training and clustering\n",
        "class Word2VecModel:\n",
        "    def __init__(self, sentences, vector_size, window=5, min_count=1):\n",
        "        self.model = Word2Vec(sentences, vector_size=vector_size, window=window, min_count=min_count)\n",
        "\n",
        "    def get_embedding(self, sentence):\n",
        "        word_embeddings = [self.model.wv[word] for word in sentence if word in self.model.wv]\n",
        "        return np.mean(word_embeddings, axis=0) if word_embeddings else np.zeros(self.model.vector_size)\n",
        "\n",
        "class SentenceEmbedder:\n",
        "    def __init__(self, word2vec_model):\n",
        "        self.word2vec_model = word2vec_model\n",
        "\n",
        "    def generate_embeddings(self, sentences, normalize=False):\n",
        "        embeddings = np.array([self.word2vec_model.get_embedding(sentence) for sentence in sentences])\n",
        "        return embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True) if normalize else embeddings\n",
        "\n",
        "class SphericalKMeans:\n",
        "    def __init__(self, n_clusters=3, max_iter=100, tol=1e-4, random_state=None):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.random_state = random_state\n",
        "        self.cluster_centers_ = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        np.random.seed(self.random_state)\n",
        "        X = normalize(X, norm='l2', axis=1)\n",
        "\n",
        "        indices = np.random.choice(X.shape[0], self.n_clusters, replace=False)\n",
        "        self.cluster_centers_ = X[indices]\n",
        "\n",
        "        for _ in range(self.max_iter):\n",
        "            # Compute cosine similarity (dot product since vectors are normalized)\n",
        "            similarities = X @ self.cluster_centers_.T\n",
        "            labels = np.argmax(similarities, axis=1)\n",
        "\n",
        "            new_centroids = np.array([normalize(X[labels == j].mean(axis=0).reshape(1, -1))\n",
        "                                      if np.any(labels == j) else self.cluster_centers_[j]\n",
        "                                      for j in range(self.n_clusters)]).squeeze()\n",
        "\n",
        "            if np.linalg.norm(new_centroids - self.cluster_centers_) < self.tol:\n",
        "                break\n",
        "\n",
        "            self.cluster_centers_ = new_centroids\n",
        "\n",
        "        self.labels_ = labels\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = normalize(X, norm='l2', axis=1)\n",
        "        similarities = X @ self.cluster_centers_.T\n",
        "        return np.argmax(similarities, axis=1)\n",
        "\n",
        "    def fit_predict(self, X):\n",
        "        self.fit(X)\n",
        "        return self.labels_\n",
        "\n",
        "class ClusteringModel:\n",
        "    def __init__(self, n_clusters, method=\"spherical_kmeans\", random_state=42):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.method = method\n",
        "        self.random_state = random_state\n",
        "        self.model = self._initialize_model()\n",
        "\n",
        "    def _initialize_model(self):\n",
        "        if self.method == \"agglomerative\":\n",
        "            return AgglomerativeClustering(n_clusters=self.n_clusters, metric='cosine', linkage='average')\n",
        "        elif self.method == \"spherical_kmeans\":\n",
        "            return SphericalKMeans(n_clusters=self.n_clusters, random_state=self.random_state)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported clustering method\")\n",
        "\n",
        "    def fit_predict(self, embeddings):\n",
        "        return self.model.fit_predict(embeddings)\n",
        "\n",
        "word2vec_model = Word2VecModel(sentences, vector_size=vector_space_dimension)\n",
        "sentence_embedder = SentenceEmbedder(word2vec_model)\n",
        "embeddings = sentence_embedder.generate_embeddings(sentences, normalize=normalize)\n",
        "\n",
        "clustering_model = ClusteringModel(n_clusters, method=clustering_method)\n",
        "labels = clustering_model.fit_predict(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "ZEMXKg1JZV14"
      },
      "outputs": [],
      "source": [
        "#Decision tree training\n",
        "class DecisionTreeTrainer:\n",
        "    def __init__(self, features_raw, labels, max_depth, subgroup_size_limit, test_size, random_state=73, print_acc=True):\n",
        "        self.features_raw = features_raw\n",
        "        self.labels = labels\n",
        "        self.max_depth = max_depth\n",
        "        self.subgroup_size_limit = subgroup_size_limit\n",
        "        self.test_size = test_size\n",
        "        self.random_state = random_state\n",
        "        self.print_acc = print_acc\n",
        "\n",
        "        self.encoder = OneHotEncoder()\n",
        "        self.decision_trees = {}\n",
        "        self.accuracies = {}\n",
        "\n",
        "        self._prepare_data()\n",
        "        self._train_trees()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        features_classify = self.features_raw.assign(cluster=self.labels)\n",
        "        X = features_classify.drop(columns=['cluster'])\n",
        "        X_encoded = self.encoder.fit_transform(X)\n",
        "        y = features_classify['cluster']\n",
        "\n",
        "        self.X_df = pd.DataFrame(X_encoded.toarray(), columns=self.encoder.get_feature_names_out())\n",
        "\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            self.X_df, y, test_size=self.test_size, random_state=self.random_state, stratify=y\n",
        "        )\n",
        "\n",
        "    def _train_trees(self):\n",
        "        for cluster in sorted(self.y_train.unique()):\n",
        "            y_train_binary = (self.y_train == cluster).astype(int)\n",
        "            y_test_binary = (self.y_test == cluster).astype(int)\n",
        "\n",
        "            clf = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_leaf=self.subgroup_size_limit, random_state=self.random_state)\n",
        "            clf.fit(self.X_train, y_train_binary)\n",
        "\n",
        "            self.decision_trees[cluster] = clf\n",
        "\n",
        "            y_pred = clf.predict(self.X_test)\n",
        "            accuracy = accuracy_score(y_test_binary, y_pred)\n",
        "            self.accuracies[cluster] = accuracy\n",
        "\n",
        "            if self.print_acc:\n",
        "                print(f\"Accuracy for Cluster {cluster}: {accuracy:.4f}\")\n",
        "                print(classification_report(y_test_binary, y_pred))\n",
        "\n",
        "    def get_trees(self):\n",
        "        return self.decision_trees\n",
        "\n",
        "    def get_accuracies(self):\n",
        "        return self.accuracies\n",
        "\n",
        "tree_trainer = DecisionTreeTrainer(\n",
        "    features_raw=features_raw,\n",
        "    labels=labels,\n",
        "    max_depth=max_depth,\n",
        "    subgroup_size_limit=subgroup_size_limit,\n",
        "    test_size=test_size,\n",
        "    print_acc=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "F25s3scoulEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7814900d-03a3-471e-8c71-968227820612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Formatted Cluster Summary:\n",
            "Cluster 0: support = 240, 'poisonous': 0.8, 'edible': 0.2, WRAcc = 0.022935489571901408\n",
            "  - odor_creosote <= 0.50 AND ring-type_flaring > 0.50\n",
            "  - odor_creosote > 0.50\n",
            "Cluster 1: support = 32, 'poisonous': 1.0, WRAcc = 0.0039234310336509854\n",
            "  - stalk-color-below-ring_yellow > 0.50\n",
            "Cluster 2: support = 6, 'poisonous': 1.0, WRAcc = 0.0007380069775205148\n",
            "  - No rules extracted\n",
            "Cluster 3: support = 18, 'poisonous': 1.0, WRAcc = 0.0022107481743463757\n",
            "  - stalk-color-above-ring_cinnamon > 0.50 AND gill-attachment_attached <= 0.50\n",
            "Cluster 4: support = 48, 'edible': 1.0, WRAcc = 0.005873510076822545\n",
            "  - cap-color_cinnamon > 0.50 AND gill-spacing_close <= 0.50\n",
            "Cluster 5: support = 8, 'poisonous': 1.0, WRAcc = 0.0009837668768262295\n",
            "  - No rules extracted\n",
            "Cluster 6: support = 352, 'poisonous': 0.73, 'edible': 0.27, WRAcc = 0.03014622441278839\n",
            "  - odor_pungent > 0.50\n",
            "Cluster 7: support = 104, 'poisonous': 0.69, 'edible': 0.31, WRAcc = 0.00874917362855067\n",
            "  - spore-print-color_green > 0.50\n",
            "Cluster 8: support = 18, 'poisonous': 1.0, WRAcc = 0.0022107481743463757\n",
            "  - stalk-color-above-ring_cinnamon > 0.50 AND gill-attachment_attached > 0.50\n",
            "Cluster 9: support = 2, 'poisonous': 1.0, WRAcc = 0.00024612353910740005\n",
            "  - No rules extracted\n",
            "Cluster 10: support = 192, 'edible': 1.0, WRAcc = 0.0230751272557486\n",
            "  - stalk-color-above-ring_orange > 0.50\n",
            "Cluster 11: support = 192, 'edible': 1.0, WRAcc = 0.0230751272557486\n",
            "  - habitat_waste > 0.50\n",
            "Cluster 12: support = 1728, 'poisonous': 1.0, WRAcc = 0.16746049235374588\n",
            "  - gill-color_buff > 0.50\n",
            "Cluster 13: support = 16, 'edible': 1.0, WRAcc = 0.0019655943413768033\n",
            "  - stalk-surface-above-ring_scaly > 0.50\n",
            "Cluster 14: support = 768, 'edible': 1.0, WRAcc = 0.08559790019832916\n",
            "  - stalk-root_equal > 0.50 AND gill-size_broad > 0.50\n",
            "Cluster 15: support = 240, 'edible': 1.0, WRAcc = 0.02866936196487676\n",
            "  - ring-number_two > 0.50 AND gill-spacing_close <= 0.50\n",
            "Cluster 16: support = 192, 'edible': 1.0, WRAcc = 0.0230751272557486\n",
            "  - stalk-root_rooted > 0.50\n",
            "Cluster 17: support = 1728, 'edible': 1.0, WRAcc = 0.16746049235374588\n",
            "  - habitat_woods > 0.50 AND odor_none > 0.50\n",
            "Cluster 18: support = 288, 'poisonous': 1.0, WRAcc = 0.03419377783208132\n",
            "  - habitat_urban > 0.50 AND gill-size_broad > 0.50\n",
            "Cluster 19: support = 1296, 'poisonous': 1.0, WRAcc = 0.13407835855902636\n",
            "  - ring-type_large > 0.50\n",
            "Cluster 20: support = 48, 'edible': 1.0, WRAcc = 0.005873510076822545\n",
            "  - No rules extracted\n",
            "Cluster 21: support = 512, 'edible': 1.0, WRAcc = 0.05905122496915729\n",
            "  - stalk-root_club > 0.50 AND stalk-color-below-ring_white > 0.50\n",
            "Cluster 22: support = 96, 'edible': 1.0, WRAcc = 0.011677201311721492\n",
            "  - spore-print-color_purple > 0.50\n",
            "\n",
            "Unextractable Clusters: [2, 5, 9, 20]\n"
          ]
        }
      ],
      "source": [
        "# Subgroup creation and quality evaluation\n",
        "def Quality_metric(tp, fp, TP, FP, description_length, description_length_limit, difference_limit, subgroup_size_limit):\n",
        "    difference = abs(tp / (tp + fp) - (TP / (TP + FP)))\n",
        "    if difference < difference_limit or description_length > description_length_limit or (tp + fp) < subgroup_size_limit:\n",
        "        return np.NaN\n",
        "    return difference / description_length\n",
        "\n",
        "class ClusterRuleExtractor:\n",
        "    def __init__(self, data_frame, target_df, mixed_threshold, cluster_labels, feature_names, decision_trees, trees_acc, tree_accuracy_threshold):\n",
        "        self.data_frame = data_frame\n",
        "        self.target_df = target_df\n",
        "        self.mixed_threshold = mixed_threshold\n",
        "        self.cluster_labels = cluster_labels\n",
        "        self.feature_names = feature_names\n",
        "        self.decision_trees = decision_trees\n",
        "        self.trees_acc = trees_acc\n",
        "        self.tree_accuracy_threshold = tree_accuracy_threshold\n",
        "\n",
        "        self.cluster_frequencies = {}\n",
        "        self.cluster_percentages = {}\n",
        "        self.rules_dict = {}\n",
        "        self.unextractable_clusters = []\n",
        "        self.WRAcc_dict = {}\n",
        "        self.tp_dict = {}\n",
        "        self.fp_dict = {}\n",
        "        self.TP_dict = {}\n",
        "        self.FP_dict = {}\n",
        "\n",
        "        self._classify_and_extract_rules()\n",
        "\n",
        "    def _extract_rules_from_tree(self, tree, node=0, rule_list=None, rule_path=None):\n",
        "        if rule_list is None:\n",
        "            rule_list = []\n",
        "        if rule_path is None:\n",
        "            rule_path = []\n",
        "\n",
        "        left_child = tree.tree_.children_left[node]\n",
        "        right_child = tree.tree_.children_right[node]\n",
        "        threshold = tree.tree_.threshold[node]\n",
        "        feature = tree.tree_.feature[node]\n",
        "        value = tree.tree_.value[node]\n",
        "\n",
        "        if left_child == -1 and right_child == -1:\n",
        "            class_probabilities = value[0] / value.sum()\n",
        "            predicted_class = class_probabilities.argmax()\n",
        "            if predicted_class == 1:\n",
        "                rule_list.append(\" AND \".join(rule_path))\n",
        "            return rule_list\n",
        "\n",
        "        if left_child != -1:\n",
        "            self._extract_rules_from_tree(tree, left_child, rule_list, rule_path + [f\"{self.feature_names[feature]} <= {threshold:.2f}\"])\n",
        "\n",
        "        if right_child != -1:\n",
        "            self._extract_rules_from_tree(tree, right_child, rule_list, rule_path + [f\"{self.feature_names[feature]} > {threshold:.2f}\"])\n",
        "\n",
        "        return rule_list\n",
        "\n",
        "    def _classify_and_extract_rules(self):\n",
        "        cluster_class_counts = {}\n",
        "        for i, cluster in enumerate(self.cluster_labels):\n",
        "            class_label = self.target_df['class'][i]\n",
        "            cluster_class_counts.setdefault(cluster, {}).setdefault(class_label, 0)\n",
        "            cluster_class_counts[cluster][class_label] += 1\n",
        "\n",
        "        N = len(self.target_df)\n",
        "        class_counts = {class_: sum(self.target_df['class'] == class_) for class_ in set(self.target_df['class'])}\n",
        "        cluster_classifications, n_dict = {}, {}\n",
        "\n",
        "        for cluster, class_counts in sorted(cluster_class_counts.items()):\n",
        "            total_count = sum(class_counts.values())\n",
        "            class_percentages = {cls: round(count / total_count, 2) for cls, count in class_counts.items()}\n",
        "            dominant_class, dominant_count = max(class_counts.items(), key=lambda x: x[1])\n",
        "            relative_frequency = dominant_count / total_count\n",
        "            classification = dominant_class if relative_frequency >= self.mixed_threshold else 'mixed'\n",
        "\n",
        "            cluster_classifications[cluster] = classification\n",
        "            self.cluster_frequencies[cluster] = total_count\n",
        "            self.cluster_percentages[cluster] = class_percentages\n",
        "            self.tp_dict[cluster] = dominant_count\n",
        "            self.fp_dict[cluster] = total_count - dominant_count\n",
        "            n_dict[cluster] = total_count\n",
        "\n",
        "            self.TP_dict[cluster] = class_counts.get(dominant_class, 0)\n",
        "            self.FP_dict[cluster] = N - self.TP_dict[cluster]\n",
        "\n",
        "            self.WRAcc_dict[cluster] = ((self.tp_dict[cluster] + self.fp_dict[cluster]) / N) * (self.tp_dict[cluster] / n_dict[cluster] - self.TP_dict[cluster] / N)\n",
        "\n",
        "            if cluster in self.decision_trees:\n",
        "                accuracy = self.trees_acc.get(cluster, 0)\n",
        "                if accuracy < self.tree_accuracy_threshold:\n",
        "                    self.unextractable_clusters.append(cluster)\n",
        "                    self.rules_dict[cluster] = [\"Accuracy lower than the given threshold\"]\n",
        "                else:\n",
        "                    rules_list = self._extract_rules_from_tree(self.decision_trees[cluster])\n",
        "                    self.rules_dict[cluster] = rules_list if rules_list else self.unextractable_clusters.append(cluster)\n",
        "            else:\n",
        "                self.unextractable_clusters.append(cluster)\n",
        "\n",
        "\n",
        "\n",
        "    def print_summary(self):\n",
        "        print(\"\\nFormatted Cluster Summary:\")\n",
        "        for cluster in sorted(self.cluster_frequencies.keys()):\n",
        "            percentages_str = \", \".join(f\"'{cls}': {perc}\" for cls, perc in self.cluster_percentages[cluster].items())\n",
        "            rules = self.rules_dict.get(cluster, None)\n",
        "\n",
        "            if rules is None:\n",
        "                rules = [\"No rules extracted\"]\n",
        "\n",
        "            print(f\"Cluster {cluster}: support = {self.cluster_frequencies[cluster]}, {percentages_str}, WRAcc = {self.WRAcc_dict[cluster]}\")\n",
        "\n",
        "            for rule in rules:\n",
        "                print(f\"  - {rule}\")\n",
        "\n",
        "        print(\"\\nUnextractable Clusters:\", self.unextractable_clusters)\n",
        "\n",
        "\n",
        "clusters = ClusterRuleExtractor(\n",
        "    data_frame=training_df,\n",
        "    target_df=target_df,\n",
        "    mixed_threshold=mixed_threshold,\n",
        "    cluster_labels=labels,\n",
        "    feature_names=list(tree_trainer.X_df.columns),\n",
        "    decision_trees=tree_trainer.get_trees(),\n",
        "    trees_acc=tree_trainer.get_accuracies(),\n",
        "    tree_accuracy_threshold=tree_accuracy_threshold\n",
        ")\n",
        "clusters.print_summary()"
      ]
    },
    {
      "source": [
        "class SubgroupCreator:\n",
        "    def __init__(self, X_df, targets_df, target_value):\n",
        "        self.X_df = X_df\n",
        "        self.targets_df = targets_df\n",
        "        self.target_value = target_value\n",
        "        self.tp_dict = {}\n",
        "        self.fp_dict = {}\n",
        "        self.TP_dict = {}\n",
        "        self.FP_dict = {}\n",
        "        self.WRAcc_dict = {}\n",
        "        self.Quality_dict = {}\n",
        "        self.subgroups = {}\n",
        "        self.total_coverage = 0\n",
        "        self.subgroup_descriptions = {}\n",
        "\n",
        "    def evaluate_rule(self, rule_str, covered_indices_set):\n",
        "        parts = rule_str.split(\" AND \")\n",
        "        mask = pd.Series(True, index=self.X_df.index)\n",
        "\n",
        "        description = []\n",
        "\n",
        "        for part in parts:\n",
        "            feature, operator, value = part.split()\n",
        "            value = float(value)\n",
        "\n",
        "            if \">\" in operator:\n",
        "                feature_name = feature.rsplit(\"_\", 1)[0]\n",
        "                category_value = feature.split(\"_\")[-1]\n",
        "                description.append(f\"{feature_name} = '{category_value}'\")\n",
        "                mask &= self.X_df[feature] > 0.5\n",
        "\n",
        "            elif \"<=\" in operator:\n",
        "                feature_name = feature.rsplit(\"_\", 1)[0]\n",
        "                category_value = feature.split(\"_\")[-1]\n",
        "                description.append(f\"{feature_name} ≠ '{category_value}'\")\n",
        "                mask &= self.X_df[feature] <= 0.5\n",
        "\n",
        "        covered_indices = set(self.X_df[mask].index) - covered_indices_set\n",
        "        covered_indices_set.update(covered_indices)\n",
        "        covered_targets = self.targets_df.loc[list(covered_indices)]\n",
        "\n",
        "        tp = (covered_targets == self.target_value).sum().item()\n",
        "        fp = (covered_targets != self.target_value).sum().item()\n",
        "        TP = (self.targets_df == self.target_value).sum().item()\n",
        "        FP = (self.targets_df != self.target_value).sum().item()\n",
        "\n",
        "        WRAcc = ((tp + fp) / (TP + FP)) * ((tp / (tp + fp)) - (TP / (TP + FP)))\n",
        "\n",
        "        return tp, fp, TP, FP, WRAcc, covered_indices, description\n",
        "\n",
        "    def evaluate_all_clusters(self, subgroups):\n",
        "        with open(\"results_SDUEBA.txt\", \"w\") as f:\n",
        "            for cluster, rules_list in subgroups.rules_dict.items():\n",
        "                if cluster not in subgroups.unextractable_clusters:\n",
        "                    covered_indices_set = set()\n",
        "\n",
        "                    for idx, rule_str in enumerate(rules_list):\n",
        "                        letter_index = string.ascii_lowercase[idx]\n",
        "                        subgroup_label = f\"{cluster}.{letter_index}\"\n",
        "\n",
        "                        tp, fp, TP, FP, WRAcc, covered_indices, description = self.evaluate_rule(rule_str, covered_indices_set)\n",
        "\n",
        "                        self.tp_dict[subgroup_label] = tp\n",
        "                        self.fp_dict[subgroup_label] = fp\n",
        "                        self.TP_dict[subgroup_label] = TP\n",
        "                        self.FP_dict[subgroup_label] = FP\n",
        "                        self.WRAcc_dict[subgroup_label] = WRAcc\n",
        "                        self.subgroups[subgroup_label] = covered_indices\n",
        "                        self.total_coverage += tp + fp\n",
        "\n",
        "                        description_str = \", \".join(str(item) for item in description)\n",
        "                        self.Quality_dict[subgroup_label] = Quality_metric(\n",
        "                            tp=tp,\n",
        "                            fp=fp,\n",
        "                            TP=TP,\n",
        "                            FP=FP,\n",
        "                            description_length=len(description),\n",
        "                            description_length_limit=description_length_limit,\n",
        "                            difference_limit=difference_limit,\n",
        "                            subgroup_size_limit=subgroup_size_limit,\n",
        "                        )\n",
        "                        self.subgroup_descriptions[subgroup_label] = description_str\n",
        "\n",
        "\n",
        "                        f.write(\n",
        "                            f\"Description: [{description_str}], Target: class = '{self.target_value}' ; \"\n",
        "                            f\"QuMe = {float(self.Quality_dict[subgroup_label]) if self.Quality_dict[subgroup_label] is not None else 0:.8f} ; \"\n",
        "                            f\"WRAcc = {float(WRAcc) if WRAcc is not None else 0:.8f} ; \"\n",
        "                            f\"tp = {tp} ; fp = {fp} ; TP = {TP} ; FP = {FP}\\n\"\n",
        "                        )\n",
        "            f.write(f\"Total coverage: {self.total_coverage / len(self.targets_df)}\\n\")\n",
        "\n",
        "\n",
        "evaluator = SubgroupCreator(tree_trainer.X_df, target_df, target_value=target_value)\n",
        "evaluator.evaluate_all_clusters(clusters)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0sGjZPlez685"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iVmTJO_0MjND"
      },
      "outputs": [],
      "source": [
        "# # Clusters visualization\n",
        "# def plot_sentence_embeddings(embeddings, cluster_labels=None, target_labels=None, clustering_method=None):\n",
        "#     plt.figure(figsize=(15, 10))\n",
        "#     tsne = TSNE(n_components=2, random_state= 73, perplexity=300, learning_rate=200, max_iter=1000)\n",
        "#     embeddings_2d = tsne.fit_transform(np.array(embeddings))\n",
        "#     cmap = plt.colormaps['hsv']\n",
        "\n",
        "\n",
        "#     n_clusters = len(set(cluster_labels))\n",
        "#     colors = cmap(np.linspace(0, 1, n_clusters))\n",
        "#     handles = [plt.Line2D([], [], color=color) for color in colors]\n",
        "#     labels = [f\"Cluster {i}\" for i in range(n_clusters)]\n",
        "#     scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors[cluster_labels])\n",
        "\n",
        "#     plt.legend(handles=handles, labels=labels, title=f\"Clusters created with {clustering_method}\", loc = \"upper right\")\n",
        "#     plt.title(f\"Sentence Embeddings Visualization\")\n",
        "# plot_sentence_embeddings(embeddings, cluster_labels=labels, clustering_method=f\"Clustering method {clustering_method}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from subgroups.algorithms import BSD\n",
        "from subgroups.quality_measures import WRAcc\n",
        "from subgroups.quality_measures import WRAccOptimisticEstimate1\n",
        "\n",
        "dataset = pd.concat([features_raw, target_df], axis=1).astype(str)\n",
        "target = ('class', target_value)\n",
        "#num_subgroups=50!!!!\n",
        "bsd_model = BSD(min_support=0, quality_measure=WRAcc(), optimistic_estimate = WRAccOptimisticEstimate1(), num_subgroups=50, max_depth=2, write_results_in_file = True, file_path = \"./results_BSD.txt\" )\n",
        "bsd_model.fit(dataset, target)\n"
      ],
      "metadata": {
        "id": "p2XsZDoTRmrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf22686-e0e2-4022-9496-358c07f8a527"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.16 s, sys: 110 ms, total: 2.27 s\n",
            "Wall time: 2.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hHAi82WqRkc5"
      },
      "outputs": [],
      "source": [
        "def parse_and_compute_quality(file_path, description_length_limit, difference_limit, subgroup_size_limit):\n",
        "    output_file = \"results_BSD_.txt\"\n",
        "\n",
        "    with open(file_path, 'r') as file, open(output_file, 'w') as output:\n",
        "        for line in file:\n",
        "            match = re.search(r\"(Description: \\[.*?\\]), Target: (.*?) ; Quality Measure WRAcc = ([\\d.-]+) ; tp = (\\d+) ; fp = (\\d+) ; TP = (\\d+) ; FP = (\\d+)\", line)\n",
        "\n",
        "            if match:\n",
        "                description = match.group(1)\n",
        "                target = match.group(2)\n",
        "                WRAcc = float(match.group(3))\n",
        "                tp = int(match.group(4))\n",
        "                fp = int(match.group(5))\n",
        "                TP = int(match.group(6))\n",
        "                FP = int(match.group(7))\n",
        "\n",
        "                description_text = description[13:-1]\n",
        "                description_length = description_text.count(',') + 1 if description_text else 1\n",
        "\n",
        "                quality_score = Quality_metric(tp, fp, TP, FP, description_length, description_length_limit, difference_limit, subgroup_size_limit)\n",
        "\n",
        "                output_line = f\"{description}, Target: {target} ; QuMe = {quality_score:.8f} ; WRAcc = {WRAcc:.8f} ; tp = {tp} ; fp = {fp} ; TP = {TP} ; FP = {FP}\\n\"\n",
        "                output.write(output_line)\n",
        "\n",
        "file_path = \"results_BSD.txt\"\n",
        "parse_and_compute_quality(file_path, description_length_limit, difference_limit, subgroup_size_limit)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Overlap ratio\n",
        "def compute_coverage(filename, quality_measure, k, dataset, print_subgroups=False):\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    subgroups = []\n",
        "    instance_coverage = {}\n",
        "\n",
        "    for line in lines:\n",
        "        match = re.search(rf\"{quality_measure}\\s*=\\s*([-+]?\\d*\\.?\\d+)\\s*;.*tp\\s*=\\s*(\\d+)\\s*;\\s*fp\\s*=\\s*(\\d+)\", line)\n",
        "        if match:\n",
        "            quality = float(match.group(1))\n",
        "            tp = int(match.group(2))\n",
        "            fp = int(match.group(3))\n",
        "\n",
        "            desc_match = re.search(r\"Description: \\[(.*?)\\]\", line)\n",
        "            if desc_match:\n",
        "                description = desc_match.group(1).split(\", \")\n",
        "            else:\n",
        "                description = []\n",
        "\n",
        "            mask = pd.Series(True, index=dataset.index)\n",
        "            for condition in description:\n",
        "                try:\n",
        "                    feature, value = condition.split(\" = \")\n",
        "                    value = value.strip(\"'\")\n",
        "\n",
        "                    if feature not in dataset.columns:\n",
        "                        continue\n",
        "\n",
        "                    mask &= dataset[feature] == value\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "            covered_instances = set(dataset[mask].index)\n",
        "\n",
        "            for instance in covered_instances:\n",
        "                instance_coverage[instance] = instance_coverage.get(instance, 0) + 1\n",
        "\n",
        "            subgroups.append((quality, covered_instances, description, line.strip()))\n",
        "\n",
        "    subgroups.sort(reverse=True, key=lambda x: x[0])\n",
        "    top_k_subgroups = subgroups[:k]\n",
        "\n",
        "    covered_instances = set()\n",
        "    filtered_instance_coverage = {}\n",
        "\n",
        "    for _, instance_ids, _, _ in top_k_subgroups:\n",
        "        covered_instances.update(instance_ids)\n",
        "        for instance in instance_ids:\n",
        "            filtered_instance_coverage[instance] = filtered_instance_coverage.get(instance, 0) + 1\n",
        "\n",
        "    coverage = len(covered_instances) / len(dataset) if len(dataset) else 0\n",
        "    overlapping_instances = sum(1 for count in filtered_instance_coverage.values() if count > 1)\n",
        "    overlap_ratio = overlapping_instances / len(covered_instances) if covered_instances else 0\n",
        "\n",
        "    if print_subgroups:\n",
        "        print(\"Top-k subgroups:\")\n",
        "        for _, _, _, subgroup in top_k_subgroups:\n",
        "            print(subgroup)\n",
        "\n",
        "    return coverage, overlap_ratio\n",
        "\n",
        "\n",
        "print(\"SDUEBA model:\")\n",
        "coverage_SDUEBA, overlap_SDUEBA = compute_coverage('results_SDUEBA.txt', 'QuMe', n_clusters, features_raw, True)\n",
        "print(f\"Coverage: {coverage_SDUEBA}, Overlap Ratio: {overlap_SDUEBA}\")\n",
        "\n",
        "print(\"BSD model:\")\n",
        "coverage_BSD, overlap_BSD = compute_coverage('results_BSD_.txt', 'QuMe', n_clusters, features_raw, True)\n",
        "print(f\"Coverage: {coverage_BSD}, Overlap Ratio: {overlap_BSD}\")"
      ],
      "metadata": {
        "id": "w49PJtYLgoFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611c7dd5-52d4-4db4-b1f1-508eeeb54652"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDUEBA model:\n",
            "Top-k subgroups:\n",
            "Description: [odor = 'creosote'], Target: class = 'poisonous' ; QuMe = 0.51797144 ; WRAcc = 0.01224157 ; tp = 192 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [stalk-color-below-ring = 'yellow'], Target: class = 'poisonous' ; QuMe = 0.51797144 ; WRAcc = 0.00153020 ; tp = 24 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [odor = 'pungent'], Target: class = 'poisonous' ; QuMe = 0.51797144 ; WRAcc = 0.01632209 ; tp = 256 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [spore-print-color = 'green'], Target: class = 'poisonous' ; QuMe = 0.51797144 ; WRAcc = 0.00459059 ; tp = 72 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [gill-color = 'buff'], Target: class = 'poisonous' ; QuMe = 0.51797144 ; WRAcc = 0.11017413 ; tp = 1728 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [ring-type = 'large'], Target: class = 'poisonous' ; QuMe = 0.51797144 ; WRAcc = 0.08263060 ; tp = 1296 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [stalk-color-above-ring = 'orange'], Target: class = 'poisonous' ; QuMe = 0.48202856 ; WRAcc = -0.01139211 ; tp = 0 ; fp = 192 ; TP = 3916 ; FP = 4208\n",
            "Description: [habitat = 'waste'], Target: class = 'poisonous' ; QuMe = 0.48202856 ; WRAcc = -0.01139211 ; tp = 0 ; fp = 192 ; TP = 3916 ; FP = 4208\n",
            "Description: [stalk-root = 'rooted'], Target: class = 'poisonous' ; QuMe = 0.48202856 ; WRAcc = -0.01139211 ; tp = 0 ; fp = 192 ; TP = 3916 ; FP = 4208\n",
            "Description: [spore-print-color = 'purple'], Target: class = 'poisonous' ; QuMe = 0.48202856 ; WRAcc = -0.00284803 ; tp = 0 ; fp = 48 ; TP = 3916 ; FP = 4208\n",
            "Description: [stalk-color-above-ring = 'cinnamon', gill-attachment ≠ 'attached'], Target: class = 'poisonous' ; QuMe = 0.25898572 ; WRAcc = 0.00114765 ; tp = 18 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [stalk-color-above-ring = 'cinnamon', gill-attachment = 'attached'], Target: class = 'poisonous' ; QuMe = 0.25898572 ; WRAcc = 0.00114765 ; tp = 18 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [habitat = 'urban', gill-size = 'broad'], Target: class = 'poisonous' ; QuMe = 0.25898572 ; WRAcc = 0.00918118 ; tp = 144 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [odor ≠ 'creosote', ring-type = 'flaring'], Target: class = 'poisonous' ; QuMe = 0.24101428 ; WRAcc = -0.00284803 ; tp = 0 ; fp = 48 ; TP = 3916 ; FP = 4208\n",
            "Description: [cap-color = 'cinnamon', gill-spacing ≠ 'close'], Target: class = 'poisonous' ; QuMe = 0.24101428 ; WRAcc = -0.00142401 ; tp = 0 ; fp = 24 ; TP = 3916 ; FP = 4208\n",
            "Description: [stalk-root = 'equal', gill-size = 'broad'], Target: class = 'poisonous' ; QuMe = 0.24101428 ; WRAcc = -0.04556843 ; tp = 0 ; fp = 768 ; TP = 3916 ; FP = 4208\n",
            "Description: [ring-number = 'two', gill-spacing ≠ 'close'], Target: class = 'poisonous' ; QuMe = 0.24101428 ; WRAcc = -0.01708816 ; tp = 0 ; fp = 288 ; TP = 3916 ; FP = 4208\n",
            "Description: [stalk-root = 'club', stalk-color-below-ring = 'white'], Target: class = 'poisonous' ; QuMe = 0.24101428 ; WRAcc = -0.03037895 ; tp = 0 ; fp = 512 ; TP = 3916 ; FP = 4208\n",
            "Description: [habitat = 'woods', odor = 'none'], Target: class = 'poisonous' ; QuMe = 0.23220371 ; WRAcc = -0.10381141 ; tp = 32 ; fp = 1784 ; TP = 3916 ; FP = 4208\n",
            "Description: [stalk-surface-above-ring = 'scaly'], Target: class = 'poisonous' ; QuMe = 0.14869522 ; WRAcc = -0.00043928 ; tp = 8 ; fp = 16 ; TP = 3916 ; FP = 4208\n",
            "Coverage: 0.9606105366814377, Overlap Ratio: 0.04920553562275756\n",
            "BSD model:\n",
            "Top-k subgroups:\n",
            "Description: [odor = 'foul'], Target: class = 'poisonous' ; QuMe = 0.51797144 ; WRAcc = 0.13771767 ; tp = 2160 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [gill-size = 'narrow'], Target: class = 'poisonous' ; QuMe = 0.40332176 ; WRAcc = 0.12471003 ; tp = 2224 ; fp = 288 ; TP = 3916 ; FP = 4208\n",
            "Description: [spore-print-color = 'white'], Target: class = 'poisonous' ; QuMe = 0.27676541 ; WRAcc = 0.08135350 ; tp = 1812 ; fp = 576 ; TP = 3916 ; FP = 4208\n",
            "Description: [bruises = 'no bruises', stalk-color-below-ring = 'pink'], Target: class = 'poisonous' ; QuMe = 0.25898572 ; WRAcc = 0.08263060 ; tp = 1296 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [bruises = 'no bruises', stalk-color-above-ring = 'pink'], Target: class = 'poisonous' ; QuMe = 0.25898572 ; WRAcc = 0.08263060 ; tp = 1296 ; fp = 0 ; TP = 3916 ; FP = 4208\n",
            "Description: [gill-size = 'narrow', spore-print-color = 'white'], Target: class = 'poisonous' ; QuMe = 0.24582783 ; WRAcc = 0.11038650 ; tp = 1776 ; fp = 48 ; TP = 3916 ; FP = 4208\n",
            "Description: [bruises = 'no bruises', habitat = 'woods'], Target: class = 'poisonous' ; QuMe = 0.23783769 ; WRAcc = 0.07752267 ; tp = 1268 ; fp = 56 ; TP = 3916 ; FP = 4208\n",
            "Description: [bruises = 'no bruises', cap-surface = 'scaly'], Target: class = 'poisonous' ; QuMe = 0.23477265 ; WRAcc = 0.09548115 ; tp = 1572 ; fp = 80 ; TP = 3916 ; FP = 4208\n",
            "Description: [gill-size = 'narrow', gill-spacing = 'close'], Target: class = 'poisonous' ; QuMe = 0.22707083 ; WRAcc = 0.12611319 ; tp = 2112 ; fp = 144 ; TP = 3916 ; FP = 4208\n",
            "Description: [bruises = 'no bruises', gill-size = 'narrow'], Target: class = 'poisonous' ; QuMe = 0.21437606 ; WRAcc = 0.11357392 ; tp = 1960 ; fp = 192 ; TP = 3916 ; FP = 4208\n",
            "Description: [bruises = 'no bruises'], Target: class = 'poisonous' ; QuMe = 0.21131601 ; WRAcc = 0.12350177 ; tp = 3292 ; fp = 1456 ; TP = 3916 ; FP = 4208\n",
            "Description: [gill-size = 'narrow', population = 'several'], Target: class = 'poisonous' ; QuMe = 0.20989481 ; WRAcc = 0.11368011 ; tp = 1984 ; fp = 216 ; TP = 3916 ; FP = 4208\n",
            "Description: [gill-size = 'narrow', stalk-surface-below-ring = 'smooth'], Target: class = 'poisonous' ; QuMe = 0.18867322 ; WRAcc = 0.07134467 ; tp = 1320 ; fp = 216 ; TP = 3916 ; FP = 4208\n",
            "Description: [gill-size = 'narrow', stalk-color-below-ring = 'white'], Target: class = 'poisonous' ; QuMe = 0.18206264 ; WRAcc = 0.06992066 ; tp = 1320 ; fp = 240 ; TP = 3916 ; FP = 4208\n",
            "Description: [bruises = 'no bruises', spore-print-color = 'white'], Target: class = 'poisonous' ; QuMe = 0.17735307 ; WRAcc = 0.09413422 ; tp = 1804 ; fp = 352 ; TP = 3916 ; FP = 4208\n",
            "Description: [gill-size = 'narrow', stalk-surface-above-ring = 'smooth'], Target: class = 'poisonous' ; QuMe = 0.17565239 ; WRAcc = 0.06849665 ; tp = 1320 ; fp = 264 ; TP = 3916 ; FP = 4208\n",
            "Description: [population = 'several', veil-color = 'white'], Target: class = 'poisonous' ; QuMe = 0.12004049 ; WRAcc = 0.11655334 ; tp = 2848 ; fp = 1096 ; TP = 3916 ; FP = 4208\n",
            "Description: [bruises = 'no bruises', veil-color = 'white'], Target: class = 'poisonous' ; QuMe = 0.12002354 ; WRAcc = 0.13438382 ; tp = 3284 ; fp = 1264 ; TP = 3916 ; FP = 4208\n",
            "Description: [bruises = 'no bruises', gill-attachment = 'free'], Target: class = 'poisonous' ; QuMe = 0.11971732 ; WRAcc = 0.13374623 ; tp = 3274 ; fp = 1264 ; TP = 3916 ; FP = 4208\n",
            "Description: [gill-spacing = 'close', veil-color = 'white'], Target: class = 'poisonous' ; QuMe = 0.04629690 ; WRAcc = 0.07545186 ; tp = 3804 ; fp = 2816 ; TP = 3916 ; FP = 4208\n",
            "Coverage: 1.0, Overlap Ratio: 0.7833579517479075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fB6l3HaEpnN4"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4befMX4wvAItQic7U2Zpc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}