{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afix0/BP/blob/main/SDUEBA_006_mushroom_x_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja2FYADmALao",
        "outputId": "7afaec0c-8d5f-4c0d-8821-c82d4a60b7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "#Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.manifold import TSNE\n",
        "# from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import KMeans as SphericalKMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import export_text\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import os\n",
        "import string\n",
        "# !pip install subgroups\n",
        "\n",
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzben4ha9pYo"
      },
      "outputs": [],
      "source": [
        "#SDUEBA Parameters:\n",
        "\"\"\"\n",
        "vector_space_dimention  ... dimention of the embedding vector space\n",
        "n_clusters              ... number of clusters to be found\n",
        "max_depth               ... maximal depth of the decision tree\n",
        "test_size               ... size of the test set for training the decision tree\n",
        "mixed_threashold        ... threshold for classifying a cluster as mixed\n",
        "\"\"\"\n",
        "\n",
        "vector_space_dimention = 36\n",
        "n_clusters = 23\n",
        "max_depth = 2\n",
        "test_size = 0.2\n",
        "tree_accuracy_threshold = 0.95\n",
        "\n",
        "#Quality metric parameters\n",
        "description_length_limit = 2\n",
        "difference_limit = 0\n",
        "subgroup_size_limit = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiTDW9F9J_tX"
      },
      "outputs": [],
      "source": [
        "#Data augemntation\n",
        "def scale_dataset(df, factor=100):\n",
        "    return pd.concat([df] * factor, ignore_index=True)\n",
        "\n",
        "def preprocess_mushroom_data(df):\n",
        "\n",
        "    mapping = {\n",
        "    'cap-shape': {'b': 'bell', 'c': 'conical', 'x': 'convex', 'f': 'flat', 'k': 'knobbed', 's': 'sunken'},\n",
        "    'cap-surface': {'f': 'fibrous', 'g': 'grooves', 'y': 'scaly', 's': 'smooth'},\n",
        "    'cap-color': {'n': 'brown', 'b': 'buff', 'c': 'cinnamon', 'g': 'gray', 'r': 'green', 'p': 'pink', 'u': 'purple', 'e': 'red', 'w': 'white', 'y': 'yellow'},\n",
        "    'bruises': {'t': 'bruises', 'f': 'no bruises'},\n",
        "    'odor': {'a': 'almond', 'l': 'anise', 'c': 'creosote', 'y': 'fishy', 'f': 'foul', 'm': 'musty', 'n': 'none', 'p': 'pungent', 's': 'spicy'},\n",
        "    'gill-attachment': {'a': 'attached', 'd': 'descending', 'f': 'free', 'n': 'notched'},\n",
        "    'gill-spacing': {'c': 'close', 'w': 'crowded', 'd': 'distant'},\n",
        "    'gill-size': {'b': 'broad', 'n': 'narrow'},\n",
        "    'gill-color': {'k': 'black', 'n': 'brown', 'b': 'buff', 'h': 'chocolate', 'g': 'gray', 'r': 'green', 'o': 'orange', 'p': 'pink', 'u': 'purple', 'e': 'red', 'w': 'white', 'y': 'yellow'},\n",
        "    'stalk-shape': {'e': 'enlarging', 't': 'tapering'},\n",
        "    'stalk-root': {'b': 'bulbous', 'c': 'club', 'u': 'cup', 'e': 'equal', 'z': 'rhizomorphs', 'r': 'rooted', '?': 'missing'},\n",
        "    'stalk-surface-above-ring': {'f': 'fibrous', 'y': 'scaly', 'k': 'silky', 's': 'smooth'},\n",
        "    'stalk-surface-below-ring': {'f': 'fibrous', 'y': 'scaly', 'k': 'silky', 's': 'smooth'},\n",
        "    'stalk-color-above-ring': {'n': 'brown', 'b': 'buff', 'c': 'cinnamon', 'g': 'gray', 'o': 'orange', 'p': 'pink', 'e': 'red', 'w': 'white', 'y': 'yellow'},\n",
        "    'stalk-color-below-ring': {'n': 'brown', 'b': 'buff', 'c': 'cinnamon', 'g': 'gray', 'o': 'orange', 'p': 'pink', 'e': 'red', 'w': 'white', 'y': 'yellow'},\n",
        "    'veil-type': {'p': 'partial', 'u': 'universal'},\n",
        "    'veil-color': {'n': 'brown', 'o': 'orange', 'w': 'white', 'y': 'yellow'},\n",
        "    'ring-number': {'n': 'none', 'o': 'one', 't': 'two'},\n",
        "    'ring-type': {'c': 'cobwebby', 'e': 'evanescent', 'f': 'flaring', 'l': 'large', 'n': 'none', 'p': 'pendant', 's': 'sheathing', 'z': 'zone'},\n",
        "    'spore-print-color': {'k': 'black', 'n': 'brown', 'b': 'buff', 'h': 'chocolate', 'r': 'green', 'o': 'orange', 'u': 'purple', 'w': 'white', 'y': 'yellow'},\n",
        "    'population': {'a': 'abundant', 'c': 'clustered', 'n': 'numerous', 's': 'scattered', 'v': 'several', 'y': 'solitary'},\n",
        "    'habitat': {'g': 'grasses', 'l': 'leaves', 'm': 'meadows', 'p': 'paths', 'u': 'urban', 'w': 'waste', 'd': 'woods'}\n",
        "}\n",
        "\n",
        "    for column, mapping in mapping.items():\n",
        "        df[column] = df[column].replace(mapping)\n",
        "\n",
        "    return df\n",
        "\n",
        "mapping_targets = {'p': 'poisonous', 'e': 'edible'}\n",
        "\n",
        "data = fetch_ucirepo(id=73)\n",
        "features_raw = scale_dataset(preprocess_mushroom_data(pd.DataFrame(data=data.data.features)))\n",
        "target_df = scale_dataset(pd.DataFrame(data=data.data.targets))\n",
        "target_df.columns = ['class']\n",
        "target_df['class'] = target_df['class'].map(mapping_targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GtAP4WR2Ar3o"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "#Data augemntation sentence creation\n",
        "features_df = pd.DataFrame()\n",
        "for column in features_raw.columns:\n",
        "    split_columns = column.split(\"_\")\n",
        "    jointed_columns = ' '.join(split_columns)\n",
        "    features_df[column] = features_raw[column].apply(lambda x: f\"{jointed_columns} is {x}\")\n",
        "\n",
        "sentences = []\n",
        "for i in range(len(features_df)):\n",
        "    sentence = []\n",
        "    for word in features_df.iloc[i]:\n",
        "        sentence.append(word)\n",
        "    sentences.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEJJZRjUBXQF"
      },
      "outputs": [],
      "source": [
        "#Word2Vec training and clustering\n",
        "def sentence_embedding(sentence, model):\n",
        "    word_embeddings = []\n",
        "    for word in sentence:\n",
        "        word_embeddings.append(model.wv[word])\n",
        "    return np.mean(word_embeddings, axis=0)\n",
        "\n",
        "model = Word2Vec(sentences, min_count=1, vector_size=vector_space_dimention, window=5)\n",
        "embeddings = np.array([sentence_embedding(sentence, model) for sentence in sentences])\n",
        "#Aglomerative clustering je O(n^2)\n",
        "# labels_agglomerative_average = AgglomerativeClustering(n_clusters= n_clusters, metric = 'cosine', linkage='average').fit_predict(embeddings)\n",
        "embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "clustering_model = SphericalKMeans(n_clusters=n_clusters, random_state=42)\n",
        "labels_spherical_kmeans = clustering_model.fit_predict(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZEMXKg1JZV14"
      },
      "outputs": [],
      "source": [
        "#Decision tree training\n",
        "class DecisionTreeTrainer:\n",
        "    def __init__(self, features_raw, labels, max_depth, subgroup_size_limit, test_size, random_state=73, print_acc=True):\n",
        "        self.features_raw = features_raw\n",
        "        self.labels = labels\n",
        "        self.max_depth = max_depth\n",
        "        self.subgroup_size_limit = subgroup_size_limit\n",
        "        self.test_size = test_size\n",
        "        self.random_state = random_state\n",
        "        self.print_acc = print_acc\n",
        "\n",
        "        self.encoder = OneHotEncoder()\n",
        "        self.decision_trees = {}\n",
        "        self.accuracies = {}\n",
        "\n",
        "        self._prepare_data()\n",
        "        self._train_trees()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        features_classify = self.features_raw.assign(cluster=self.labels)\n",
        "        X = features_classify.drop(columns=['cluster'])\n",
        "        X_encoded = self.encoder.fit_transform(X)\n",
        "        y = features_classify['cluster']\n",
        "\n",
        "        self.X_df = pd.DataFrame(X_encoded.toarray(), columns=self.encoder.get_feature_names_out())\n",
        "\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            self.X_df, y, test_size=self.test_size, random_state=self.random_state, stratify=y\n",
        "        )\n",
        "\n",
        "    def _train_trees(self):\n",
        "        for cluster in sorted(self.y_train.unique()):\n",
        "            y_train_binary = (self.y_train == cluster).astype(int)\n",
        "            y_test_binary = (self.y_test == cluster).astype(int)\n",
        "\n",
        "            clf = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_leaf=self.subgroup_size_limit, random_state=self.random_state)\n",
        "            clf.fit(self.X_train, y_train_binary)\n",
        "\n",
        "            self.decision_trees[cluster] = clf\n",
        "\n",
        "            y_pred = clf.predict(self.X_test)\n",
        "            accuracy = accuracy_score(y_test_binary, y_pred)\n",
        "            self.accuracies[cluster] = accuracy\n",
        "\n",
        "            if self.print_acc:\n",
        "                print(f\"Accuracy for Cluster {cluster}: {accuracy:.4f}\")\n",
        "                print(classification_report(y_test_binary, y_pred))\n",
        "\n",
        "    def get_trees(self):\n",
        "        return self.decision_trees\n",
        "\n",
        "    def get_accuracies(self):\n",
        "        return self.accuracies\n",
        "\n",
        "tree_trainer = DecisionTreeTrainer(\n",
        "    features_raw=features_raw,\n",
        "    labels=labels_spherical_kmeans,\n",
        "    max_depth=max_depth,\n",
        "    subgroup_size_limit=subgroup_size_limit,\n",
        "    test_size=test_size,\n",
        "    print_acc=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F25s3scoulEg"
      },
      "outputs": [],
      "source": [
        "# Subgroup creation and quality evaluation\n",
        "def Quality_metric(tp, fp, TP, FP, description_length, description_length_limit, difference_limit, subgroup_size_limit):\n",
        "    difference = abs(tp / (tp + fp) - (TP / (TP + FP)))\n",
        "    if difference < difference_limit or description_length > description_length_limit or (tp + fp) < subgroup_size_limit:\n",
        "        return np.NaN\n",
        "    return difference / description_length"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cluster rule extraction\n",
        "class ClusterRuleExtractor:\n",
        "    def __init__(self, data_frame, target_df, mixed_threshold, cluster_labels, feature_names, decision_trees, trees_acc, tree_accuracy_threshold):\n",
        "        self.data_frame = data_frame\n",
        "        self.target_df = target_df\n",
        "        self.mixed_threshold = mixed_threshold\n",
        "        self.cluster_labels = cluster_labels\n",
        "        self.feature_names = feature_names\n",
        "        self.decision_trees = decision_trees\n",
        "        self.trees_acc = trees_acc\n",
        "        self.tree_accuracy_threshold = tree_accuracy_threshold\n",
        "\n",
        "        self.cluster_frequencies = {}\n",
        "        self.cluster_percentages = {}\n",
        "        self.rules_dict = {}\n",
        "        self.unextractable_clusters = []\n",
        "        self.WRAcc_dict = {}\n",
        "        self.Quality_dict = {}\n",
        "        self.tp_dict = {}\n",
        "        self.fp_dict = {}\n",
        "        self.TP_dict = {}\n",
        "        self.FP_dict = {}\n",
        "        self.description_length_dict = {}\n",
        "\n",
        "        self._classify_and_extract_rules()\n",
        "\n",
        "    def _extract_rules_from_tree(self, tree, node=0, rule_list=None, rule_path=None):\n",
        "        if rule_list is None:\n",
        "            rule_list = []\n",
        "        if rule_path is None:\n",
        "            rule_path = []\n",
        "\n",
        "        left_child = tree.tree_.children_left[node]\n",
        "        right_child = tree.tree_.children_right[node]\n",
        "        threshold = tree.tree_.threshold[node]\n",
        "        feature = tree.tree_.feature[node]\n",
        "        value = tree.tree_.value[node]\n",
        "\n",
        "        if left_child == -1 and right_child == -1:\n",
        "            class_probabilities = value[0] / value.sum()\n",
        "            predicted_class = class_probabilities.argmax()\n",
        "            if predicted_class == 1:\n",
        "                rule_list.append(\" AND \".join(rule_path))\n",
        "            return rule_list\n",
        "\n",
        "        if left_child != -1:\n",
        "            self._extract_rules_from_tree(tree, left_child, rule_list, rule_path + [f\"{self.feature_names[feature]} <= {threshold:.2f}\"])\n",
        "\n",
        "        if right_child != -1:\n",
        "            self._extract_rules_from_tree(tree, right_child, rule_list, rule_path + [f\"{self.feature_names[feature]} > {threshold:.2f}\"])\n",
        "\n",
        "        return rule_list\n",
        "\n",
        "    def _classify_and_extract_rules(self):\n",
        "        cluster_class_counts = {}\n",
        "        for i, cluster in enumerate(self.cluster_labels):\n",
        "            class_label = self.target_df['class'][i]\n",
        "            cluster_class_counts.setdefault(cluster, {}).setdefault(class_label, 0)\n",
        "            cluster_class_counts[cluster][class_label] += 1\n",
        "\n",
        "        N = len(self.target_df)\n",
        "        class_counts = {class_: sum(self.target_df['class'] == class_) for class_ in set(self.target_df['class'])}\n",
        "        cluster_classifications, n_dict = {}, {}\n",
        "\n",
        "        for cluster, class_counts in sorted(cluster_class_counts.items()):\n",
        "            total_count = sum(class_counts.values())\n",
        "            class_percentages = {cls: round(count / total_count, 2) for cls, count in class_counts.items()}\n",
        "            dominant_class, dominant_count = max(class_counts.items(), key=lambda x: x[1])\n",
        "            relative_frequency = dominant_count / total_count\n",
        "            classification = dominant_class if relative_frequency >= self.mixed_threshold else 'mixed'\n",
        "\n",
        "            cluster_classifications[cluster] = classification\n",
        "            self.cluster_frequencies[cluster] = total_count\n",
        "            self.cluster_percentages[cluster] = class_percentages\n",
        "            self.tp_dict[cluster] = dominant_count\n",
        "            self.fp_dict[cluster] = total_count - dominant_count\n",
        "            n_dict[cluster] = total_count\n",
        "\n",
        "            self.TP_dict[cluster] = class_counts.get(dominant_class, 0)\n",
        "            self.FP_dict[cluster] = N - self.TP_dict[cluster]\n",
        "\n",
        "            self.WRAcc_dict[cluster] = ((self.tp_dict[cluster] + self.fp_dict[cluster]) / N) * (self.tp_dict[cluster] / n_dict[cluster] - self.TP_dict[cluster] / N)\n",
        "\n",
        "            if cluster in self.decision_trees:\n",
        "                accuracy = self.trees_acc.get(cluster, 0)\n",
        "                if accuracy < self.tree_accuracy_threshold:\n",
        "                    self.unextractable_clusters.append(cluster)\n",
        "                    self.rules_dict[cluster] = [\"Accuracy lower than the given threshold\"]\n",
        "                    self.description_length_dict[cluster] = np.NaN\n",
        "                else:\n",
        "                    rules_list = self._extract_rules_from_tree(self.decision_trees[cluster])\n",
        "                    self.rules_dict[cluster] = rules_list if rules_list else self.unextractable_clusters.append(cluster)\n",
        "                    self.description_length_dict[cluster] = len(rules_list) if rules_list else np.NaN\n",
        "            else:\n",
        "                self.unextractable_clusters.append(cluster)\n",
        "\n",
        "            self.Quality_dict[cluster] = Quality_metric(tp=self.tp_dict[cluster],\n",
        "                                                        fp=self.fp_dict[cluster],\n",
        "                                                        TP=self.TP_dict[cluster],\n",
        "                                                        FP=self.FP_dict[cluster],\n",
        "                                                        description_length=self.description_length_dict[cluster],\n",
        "                                                        description_length_limit=description_length_limit,\n",
        "                                                        difference_limit=difference_limit,\n",
        "                                                        subgroup_size_limit=subgroup_size_limit)\n",
        "\n",
        "    def print_summary(self):\n",
        "        print(\"\\nFormatted Cluster Summary:\")\n",
        "        for cluster in sorted(self.cluster_frequencies.keys()):\n",
        "            percentages_str = \", \".join(f\"'{cls}': {perc}\" for cls, perc in self.cluster_percentages[cluster].items())\n",
        "            rules = self.rules_dict.get(cluster, None)\n",
        "\n",
        "            if rules is None or rules == \"Accuracy lower than the given threshold\":\n",
        "                rules = [\"No rules extracted (Low accuracy or unextractable)\"]\n",
        "\n",
        "            print(f\"Cluster {cluster}: support = {self.cluster_frequencies[cluster]}, {percentages_str}, WRAcc = {self.WRAcc_dict[cluster]}, Quality metric = {self.Quality_dict[cluster]}\")\n",
        "\n",
        "            for rule in rules:\n",
        "                print(f\"  - {rule}\")\n",
        "\n",
        "        print(\"\\nUnextractable Clusters:\", self.unextractable_clusters)\n",
        "\n",
        "\n",
        "clusters = ClusterRuleExtractor(\n",
        "    data_frame=features_df,\n",
        "    target_df=target_df,\n",
        "    mixed_threshold=0.9,\n",
        "    cluster_labels=labels_spherical_kmeans,\n",
        "    feature_names=list(tree_trainer.X_df.columns),\n",
        "    decision_trees=tree_trainer.get_trees(),\n",
        "    trees_acc=tree_trainer.get_accuracies(),\n",
        "    tree_accuracy_threshold=tree_accuracy_threshold\n",
        ")"
      ],
      "metadata": {
        "id": "LmCa57wOeHI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "class SubgroupCreator:\n",
        "    def __init__(self, X_df, targets_df, target_value):\n",
        "        self.X_df = X_df\n",
        "        self.targets_df = targets_df\n",
        "        self.target_value = target_value\n",
        "        self.tp_dict = {}\n",
        "        self.fp_dict = {}\n",
        "        self.TP_dict = {}\n",
        "        self.FP_dict = {}\n",
        "        self.WRAcc_dict = {}\n",
        "        self.Quality_dict = {}\n",
        "        self.subgroups = {}\n",
        "        self.total_coverage = 0\n",
        "\n",
        "    def evaluate_rule(self, rule_str, covered_indices_set):\n",
        "        parts = rule_str.split(\" AND \")\n",
        "        mask = pd.Series(True, index=self.X_df.index)\n",
        "\n",
        "        description = []\n",
        "        for part in parts:\n",
        "            feature, operator, value = part.split()\n",
        "            value = float(value)\n",
        "            if operator == \">\":\n",
        "                mask &= self.X_df[feature] > value\n",
        "            elif operator == \"<=\":\n",
        "                mask &= self.X_df[feature] <= value\n",
        "            description.append(f\"{feature} {operator} {value}\")\n",
        "\n",
        "        covered_indices = set(self.X_df[mask].index) - covered_indices_set\n",
        "        covered_indices_set.update(covered_indices)\n",
        "        covered_targets = self.targets_df.loc[list(covered_indices)]\n",
        "\n",
        "        tp = (covered_targets == self.target_value).sum().item()\n",
        "        fp = (covered_targets != self.target_value).sum().item()\n",
        "        TP = (self.targets_df == self.target_value).sum().item()\n",
        "        FP = (self.targets_df != self.target_value).sum().item()\n",
        "        WRAcc = ((tp + fp) / (TP + FP)) * ((tp / (tp + fp)) - (TP / (TP + FP)))\n",
        "\n",
        "        return tp, fp, TP, FP, WRAcc, covered_indices, description\n",
        "\n",
        "    def evaluate_all_clusters(self, subgroups):\n",
        "        with open(\"results_SDUEBA.txt\", \"w\") as f:\n",
        "            for cluster, rules_list in subgroups.rules_dict.items():\n",
        "                if cluster not in subgroups.unextractable_clusters:\n",
        "                    covered_indices_set = set()\n",
        "\n",
        "                    for idx, rule_str in enumerate(rules_list):\n",
        "                        letter_index = string.ascii_lowercase[idx]\n",
        "                        subgroup_label = f\"{cluster}.{letter_index}\"\n",
        "\n",
        "                        tp, fp, TP, FP, WRAcc, covered_indices, description = self.evaluate_rule(rule_str, covered_indices_set)\n",
        "\n",
        "                        self.tp_dict[subgroup_label] = tp\n",
        "                        self.fp_dict[subgroup_label] = fp\n",
        "                        self.TP_dict[subgroup_label] = TP\n",
        "                        self.FP_dict[subgroup_label] = FP\n",
        "                        self.WRAcc_dict[subgroup_label] = WRAcc\n",
        "                        self.subgroups[subgroup_label] = covered_indices\n",
        "                        self.total_coverage += tp + fp\n",
        "\n",
        "                        description_str = \", \".join(str(item) for item in description)\n",
        "                        self.Quality_dict[subgroup_label] = Quality_metric(\n",
        "                            tp=tp,\n",
        "                            fp=fp,\n",
        "                            TP=TP,\n",
        "                            FP=FP,\n",
        "                            description_length=len(description),\n",
        "                            description_length_limit=description_length_limit,\n",
        "                            difference_limit=difference_limit,\n",
        "                            subgroup_size_limit=subgroup_size_limit,\n",
        "                        )\n",
        "\n",
        "                        f.write(\n",
        "                            f\"Description: [{description_str}], Target: class = '{self.target_value}' ; \"\n",
        "                            f\"WRAcc = {float(WRAcc) if WRAcc is not None else 0:.8f} ; \"\n",
        "                            f\"Quality Metric = {float(self.Quality_dict[subgroup_label]) if self.Quality_dict[subgroup_label] is not None else 0:.8f} ; \"\n",
        "                            f\"tp = {tp} ; fp = {fp} ; TP = {TP} ; FP = {FP}\\n\"\n",
        "                        )\n",
        "            f.write(f\"Total coverage: {self.total_coverage / len(self.targets_df)}\\n\")\n",
        "\n",
        "\n",
        "evaluator = SubgroupCreator(tree_trainer.X_df, target_df, target_value='edible')\n",
        "evaluator.evaluate_all_clusters(clusters)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Total execution time: {end_time - start_time:.4f} seconds\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0sGjZPlez685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72245a27-068f-40d9-e812-aec862e7b0f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total execution time: 348.5876 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subgroups_to_read = n_clusters\n",
        "with open(\"./results_SDUEBA.txt\", \"r\") as file:\n",
        "    while(subgroups_to_read > 0):\n",
        "        current_line = file.readline()\n",
        "        print(current_line.strip())\n",
        "        subgroups_to_read = subgroups_to_read - 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5nvHtqdb6pM",
        "outputId": "69606521-2d2e-4930-ae35-83fa67cca580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description: [stalk-color-above-ring_gray > 0.5, stalk-color-below-ring_gray > 0.5], Target: class = 'edible' ; WRAcc = 0.01139211 ; Quality Metric = 0.24101428 ; tp = 19200 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [ring-type_large > 0.5], Target: class = 'edible' ; WRAcc = -0.08263060 ; Quality Metric = 0.51797144 ; tp = 0 ; fp = 129600 ; TP = 420800 ; FP = 391600\n",
            "Description: [stalk-root_equal > 0.5, gill-size_broad > 0.5], Target: class = 'edible' ; WRAcc = 0.04556843 ; Quality Metric = 0.24101428 ; tp = 76800 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [stalk-root_club > 0.5, stalk-color-below-ring_white > 0.5], Target: class = 'edible' ; WRAcc = 0.03037895 ; Quality Metric = 0.24101428 ; tp = 51200 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [habitat_waste > 0.5], Target: class = 'edible' ; WRAcc = 0.01139211 ; Quality Metric = 0.48202856 ; tp = 19200 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [ring-number_two > 0.5, gill-spacing_close <= 0.5], Target: class = 'edible' ; WRAcc = 0.01708816 ; Quality Metric = 0.24101428 ; tp = 28800 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [stalk-color-above-ring_orange > 0.5], Target: class = 'edible' ; WRAcc = 0.01139211 ; Quality Metric = 0.48202856 ; tp = 19200 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [odor_pungent > 0.5], Target: class = 'edible' ; WRAcc = -0.01632209 ; Quality Metric = 0.51797144 ; tp = 0 ; fp = 25600 ; TP = 420800 ; FP = 391600\n",
            "Description: [habitat_urban > 0.5, gill-size_broad > 0.5], Target: class = 'edible' ; WRAcc = -0.00918118 ; Quality Metric = 0.25898572 ; tp = 0 ; fp = 14400 ; TP = 420800 ; FP = 391600\n",
            "Description: [odor_creosote > 0.5], Target: class = 'edible' ; WRAcc = -0.01224157 ; Quality Metric = 0.51797144 ; tp = 0 ; fp = 19200 ; TP = 420800 ; FP = 391600\n",
            "Description: [stalk-color-above-ring_cinnamon <= 0.5, stalk-surface-above-ring_scaly > 0.5], Target: class = 'edible' ; WRAcc = 0.00043928 ; Quality Metric = 0.07434761 ; tp = 1600 ; fp = 800 ; TP = 420800 ; FP = 391600\n",
            "Description: [stalk-color-above-ring_cinnamon > 0.5], Target: class = 'edible' ; WRAcc = -0.00229529 ; Quality Metric = 0.51797144 ; tp = 0 ; fp = 3600 ; TP = 420800 ; FP = 391600\n",
            "Description: [stalk-root_rooted > 0.5], Target: class = 'edible' ; WRAcc = 0.01139211 ; Quality Metric = 0.48202856 ; tp = 19200 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [spore-print-color_green > 0.5], Target: class = 'edible' ; WRAcc = -0.00459059 ; Quality Metric = 0.51797144 ; tp = 0 ; fp = 7200 ; TP = 420800 ; FP = 391600\n",
            "Description: [ring-type_flaring > 0.5], Target: class = 'edible' ; WRAcc = 0.00284803 ; Quality Metric = 0.48202856 ; tp = 4800 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [cap-color_cinnamon > 0.5, gill-spacing_close <= 0.5], Target: class = 'edible' ; WRAcc = 0.00142401 ; Quality Metric = 0.24101428 ; tp = 2400 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [spore-print-color_purple <= 0.5, cap-shape_sunken > 0.5], Target: class = 'edible' ; WRAcc = 0.00189868 ; Quality Metric = 0.24101428 ; tp = 3200 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Description: [spore-print-color_purple > 0.5], Target: class = 'edible' ; WRAcc = 0.00284803 ; Quality Metric = 0.48202856 ; tp = 4800 ; fp = 0 ; TP = 420800 ; FP = 391600\n",
            "Total coverage: 0.5548990645002462\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNAYPdKKcFhI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU2cTkdvKPPRdb0KrJKWHo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}