{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhG9kk3-5b6F",
        "outputId": "c12ce4e3-351c-42f8-ede2-a0e23966d14e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting subgroups\n",
            "  Downloading subgroups-0.1.8-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from subgroups) (2.2.2)\n",
            "Collecting bitarray>=2.7.6 (from subgroups)\n",
            "  Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from subgroups) (0.14.4)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->subgroups) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->subgroups) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->subgroups) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->subgroups) (2024.2)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.14.0->subgroups) (1.13.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.14.0->subgroups) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.14.0->subgroups) (24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.14.0->subgroups) (1.16.0)\n",
            "Downloading subgroups-0.1.8-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.0/255.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitarray, subgroups\n",
            "Successfully installed bitarray-3.0.0 subgroups-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install subgroups\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE6SlJfJ52ap",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import subgroups.tests as st\n",
        "st.run_all_tests()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v2JbgO0r9PYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e53331-19f9-4e57-c8c1-28ea87912232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   longitude           1000 non-null   object\n",
            " 1   latitude            1000 non-null   object\n",
            " 2   housing_median_age  1000 non-null   object\n",
            " 3   total_rooms         1000 non-null   object\n",
            " 4   total_bedrooms      1000 non-null   object\n",
            " 5   population          1000 non-null   object\n",
            " 6   households          1000 non-null   object\n",
            " 7   median_income       1000 non-null   object\n",
            " 8   median_house_value  1000 non-null   object\n",
            " 9   ocean_proximity     1000 non-null   object\n",
            "dtypes: object(10)\n",
            "memory usage: 78.2+ KB\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "def load_housing_data():\n",
        "    tarball_path = Path(\"datasets/housing.tgz\")\n",
        "    if not tarball_path.is_file():\n",
        "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
        "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
        "        urllib.request.urlretrieve(url, tarball_path)\n",
        "        with tarfile.open(tarball_path) as housing_tarball:\n",
        "            housing_tarball.extractall(path=\"datasets\")\n",
        "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
        "# Knihovna pozaduje nominalni hodnoty\n",
        "# DatasetAttributeTypeError: Error in attribute 'longitude'. This algorithm only supports nominal attributes (i.e., type 'str').\n",
        "\n",
        "housing = load_housing_data()\n",
        "housing['longitude'] = housing['longitude'].astype(str)\n",
        "housing['latitude'] = housing['latitude'].astype(str)\n",
        "housing['ocean_proximity'] = housing['ocean_proximity'].astype(str)\n",
        "housing['households'] = housing['households'].astype(str)\n",
        "housing['total_rooms'] = housing['total_rooms'].astype(str)\n",
        "housing['total_bedrooms'] = housing['total_bedrooms'].astype(str)\n",
        "housing['population'] = housing['population'].astype(str)\n",
        "housing['median_income'] = housing['median_income'].astype(str)\n",
        "housing['median_house_value'] = housing['median_house_value'].astype(str)\n",
        "housing['housing_median_age'] = housing['housing_median_age'].astype(str)\n",
        "\n",
        "# Fitovani na cely dataset trvalo moc dlouho\n",
        "housing_reduced = housing.iloc[0:1000]\n",
        "housing_reduced.info()\n",
        "# housing_reduced.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m8C078Ox58ew"
      },
      "outputs": [],
      "source": [
        "from subgroups.quality_measures import WRAcc\n",
        "from subgroups.quality_measures import WRAccOptimisticEstimate1\n",
        "from subgroups.algorithms import VLSD\n",
        "from subgroups.algorithms import SDMapStar\n",
        "from subgroups.algorithms import SDMap\n",
        "from subgroups.algorithms import DSLM\n",
        "from subgroups.algorithms import GMSL\n",
        "from subgroups.algorithms import QFinder\n",
        "from subgroups.algorithms import BSD\n",
        "from subgroups.utils.file_format_transformations import to_input_format_for_subgroup_list_algorithms\n",
        "\n",
        "dataset = housing_reduced\n",
        "target = ('ocean_proximity', 'NEAR BAY')\n",
        "\n",
        "# Parametery jsou nastaveny stejne jako u ukazek na githubu Subgroups\n",
        "vlsd = VLSD(quality_measure = WRAcc(), q_minimum_threshold  = -1, optimistic_estimate = WRAccOptimisticEstimate1(), oe_minimum_threshold = -1, sort_criterion_in_s1 = VLSD.SORT_CRITERION_NO_ORDER, sort_criterion_in_other_sizes = VLSD.SORT_CRITERION_NO_ORDER, vertical_lists_implementation = VLSD.VERTICAL_LISTS_WITH_BITSETS, write_results_in_file = True, file_path = \"./vlsd_result.txt\")\n",
        "vlsd.fit(dataset, target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from subgroups.algorithms import DSLM\n",
        "from subgroups.utils.file_format_transformations import to_input_format_for_subgroup_list_algorithms\n",
        "\n",
        "\n",
        "subgroups_correctly_read, subgroups_not_correctly_read = to_input_format_for_subgroup_list_algorithms(\"./vlsd_result.txt\", \"./vlsd_result_transformed.txt\")\n",
        "\n",
        "\n",
        "# Ted pouzijeme DSLM pro nalezeni top-k subgroup listy\n",
        "dslm_model = DSLM(input_file_path = \"./vlsd_result_transformed.txt\",\n",
        "                  max_sl = 3,\n",
        "                  sl_max_size = 10,\n",
        "                  beta = 0.0,\n",
        "                  maximum_positive_overlap = 0.06,\n",
        "                  maximum_negative_overlap = 0.06,\n",
        "                  output_file_path = \"dslm_result.txt\")\n",
        "dslm_model.fit(dataset, target)"
      ],
      "metadata": {
        "id": "SG9e5gBI30QX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fodbtlbp5FSq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "6cef33ba-8bd6-4942-c1c7-c271931da62e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-39bd627d7f7b>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvlsd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/subgroups/algorithms/subgroup_sets/vlsd.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, pandas_dataframe, target)\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0;31m# Get the quality value of the join of s_x and s_y.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0ms_xy_dict_of_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mQualityMeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRUE_POPULATION\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQualityMeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFALSE_POPULATION\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0ms_xy_dict_of_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_additional_parameters_for_the_optimistic_estimate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0ms_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimistic_estimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_xy_dict_of_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_None_if_n_is_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0;31m# Check whether n (i.e., tp+fp) is 0 or greater than 0 (in this case, 's_xy' will be None) and whether 's_xy' has quality enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "dataset = housing_reduced\n",
        "target = ('ocean_proximity', 'NEAR BAY')\n",
        "\n",
        "# Parametery jsou nastaveny stejne jako u ukazek na githubu Subgroups\n",
        "\n",
        "#vlsd pozaduje nominal values\n",
        "vlsd = VLSD(quality_measure = WRAcc(), q_minimum_threshold  = -1, optimistic_estimate = WRAccOptimisticEstimate1(), oe_minimum_threshold = -1, sort_criterion_in_s1 = VLSD.SORT_CRITERION_NO_ORDER, sort_criterion_in_other_sizes = VLSD.SORT_CRITERION_NO_ORDER, vertical_lists_implementation = VLSD.VERTICAL_LISTS_WITH_BITSETS, write_results_in_file = True, file_path = \"./vlsd_result.txt\")\n",
        "#sdmap pozaduje nominal values\n",
        "sdmap = SDMap(quality_measure = WRAcc(), minimum_quality_measure_value = -1, minimum_n = 0, write_results_in_file = True, file_path = \"./sdmap_results.txt\")\n",
        "# sdmapstar pozaduje pocet hledanych subgroup\n",
        "sdmapstar = SDMapStar(WRAcc(), WRAccOptimisticEstimate1(), 0.01, num_subgroups=3, minimum_n = 0, write_results_in_file=True, file_path=\"./sdmapstar_results.txt\")\n",
        "bsd = BSD(min_support=0, quality_measure=WRAcc(), optimistic_estimate = WRAccOptimisticEstimate1(), num_subgroups=600, max_depth=100, write_results_in_file = True, file_path = \"./bsd_results.txt\" )\n",
        "\n",
        "methods = [vlsd, sdmap, sdmapstar, bsd]\n",
        "for method in methods:\n",
        "    method.fit(dataset, target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1uI641Gnhgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subgroups found by each method:**"
      ],
      "metadata": {
        "id": "mKa9-GDrjVJa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNviW7evOJdj",
        "outputId": "5705df59-fb92-42a4-f10f-a15f36f4ee4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subgroups selected by <subgroups.algorithms.subgroup_sets.vlsd.VLSD object at 0x7f166e18ee60> :  506899\n",
            "Subgroups selected by <subgroups.algorithms.subgroup_sets.sdmap.SDMap object at 0x7f166e197990> :  506899\n",
            "Subgroups selected by <subgroups.algorithms.subgroup_sets.sdmapstar.SDMapStar object at 0x7f1665ac1620> :  11\n",
            "Subgroups selected by <subgroups.algorithms.subgroup_sets.bsd.BSD object at 0x7f1665ac14e0> :  8\n"
          ]
        }
      ],
      "source": [
        "for i in methods:\n",
        "    print(\"Subgroups selected by \" + str(i) + \" : \", i.selected_subgroups)\n",
        "  # print(\"Unselected subgroups: \", sdmap.unselected_subgroups)\n",
        "  # print(\"Visited nodes: \", sdmap.visited_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subgroup discovery (SD)**\n",
        "\n",
        "from VLSD paper:\n",
        "\n",
        ">Moreover, the populations covered\n",
        "by different subgroups **may overlap**\n",
        "\n",
        "> One disadvantage of the SD technique is the huge number of subgroups that could be\n",
        "generated (i.e., pattern explosion), and it is especially relevant when using input datasets\n",
        "with too many attributes. For this reason, the utilization of an optimistic estimate provides\n",
        "a solution of this problem when the quality measure threshold established allows not to\n",
        "explore a large part of the search space.\n",
        "\n",
        "\n",
        "> It is sometimes possible that two subgroups generated by a specific SD algorithm are\n",
        "redundant, because they represent and explain the same portion of data from a specific\n",
        "dataset.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0sqApePFm7oP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VLSD (Vertical List Subgroup Discovery)**\n",
        "\n",
        "paper: https://www.mdpi.com/1999-4893/16/6/274\n",
        "\n",
        "> Differences between this technique and others, such as clustering, pattern mining, or classification.\n",
        "Clustering and pattern mining algorithms are unsupervised and do not use an output attribute or class, while SD algorithms are supervised and generate relations (called subgroups) with respect to a **target attribute.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*// na konci clanku je benchmark VLSD vs SD-Map vs BSD vs CBSD vs CPBSD strana 16-17*\n"
      ],
      "metadata": {
        "id": "rUpwiXxDo15I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SD-Map**\n",
        "\n",
        "paper: https://link.springer.com/chapter/10.1007/11871637_6\n",
        "\n",
        "\n",
        ">  an exhaustive search method, uses frequent pattern trees (FP-Tree)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dc5dCDW4vYOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SD-Map***\n",
        "\n",
        "paper: https://link.springer.com/chapter/10.1007/978-3-642-04125-9_7\n",
        "//od 49 strany\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ">SD-Map* algorithm as a novel adaptation of the efficient SD-Map algorithm.\n",
        "Efficiently adapt exhaustive subgroup discovery for continuous target concepts.\n",
        "Basic principle of optimistic estimates is to safely prune parts of the search space...\n",
        "\n"
      ],
      "metadata": {
        "id": "1WFCoUCh1TPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q-finder**\n",
        "\n",
        "paper: https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2020.559927/full\n",
        "\n",
        "\n",
        "\n",
        ">  It combines an\n",
        "exhaustive search with a cascade of filters based on metrics assessing key credibility criteria,\n",
        "including relative risk reduction assessment, adjustment on confounding factors, individual\n",
        "feature’s contribution to the subgroup’s effect, interaction tests for assessing betweensubgroup treatment effect interactions and tests adjustment (multiple testing).\n",
        "\n"
      ],
      "metadata": {
        "id": "kkih5x_I9cOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BSD, Closed BSD and Closed on the positives BSD**\n",
        "\n",
        "paper: https://cdn.aaai.org/ocs/1262/1262-7800-1-PB.pdf\n",
        "\n",
        "\n",
        "> BSD is a subgroup discovery algorithm that introduces the concept of dominance relation between subgroups. This algorithm also uses a list of the\n",
        " best subgroups along with an optimistic estimation to prune the search space.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3ACvs6OypSQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DSLM (Diverse Subgroup Lists Miner)**\n",
        "\n",
        "paper: https://doi.org/10.1007/978-3-031-34344-5_6 //strana 45-50\n",
        "\n",
        "\n",
        "> generates subgroup\n",
        "lists based on the subgroup discovery paradigm and the minimum description\n",
        "length principle\n",
        "\n"
      ],
      "metadata": {
        "id": "oJPdWhqurads"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GMSL (Generation of Multiple Subgroup Lists)**\n",
        "\n",
        "paper: https://doi.org/10.1007/978-3-031-30047-9_21 //strana 262-273\n",
        "\n",
        "\n",
        ">  an algorithm that takes a set of\n",
        "pre-computed subgroup candidates as input and returns a collection of diverse\n",
        "top-k subgroup lists\n",
        "\n"
      ],
      "metadata": {
        "id": "395-oecbw5K7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0wF749SjFiS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}